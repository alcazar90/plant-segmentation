<h1 align="center">
  &nbsp;SegPlantFormer 别<br>
</h1>
<h2 align="center">
A Transformer-Based Model for Plant Semantic Segmentation&nbsp;
</h2>

----

<a href="https://alkzar.cl/EVIC23_poster_segplantformer.pdf" target="_blank">[EVIC23 Poster]</a>
<a href="https://api.wandb.ai/links/alcazar90/7k7k0yph" target="_blank">[W&B blogpost]</a>
<a href="https://github.com/alcazar90/plant-segmentation/blob/main/single-segmentation.ipynb" target="_blank">[Usage]</a>

About this project;

> TBC

## Future Work

- [X] Agregar _script_ `train.py` para entrenar modelos binario (vivo/muerto) para los datasets `cwt` y `dead`.
- [X] Computar la funci贸n de p茅rdida en conjunto de validaci贸n.
- [X] Agregar _logging_ W&B.
- [X] Actualizar notebook `single-segmentation.ipynb` uso de funci贸n `get_pred_label`, y en cualquier otra parte que se utilice.
- [X] Guardar m茅trica mIoU de las observaciones en _training_.
- [ ] Usar mascaras de clases que no se van a predecir en modelo single-detection, para evitar que el modelo prediga mascaras de clases que no se van a predecir, y que afectan la m茅trica IoU. Usar las mascaras para apagar lo que no queremos ver de la imagen input.
- [ ] En vez de reportar mIoU, computar una ponderaci贸n de IoU por la cantidad de clases en cada m谩scara (e.g. IoU de `normal` que tiene 3 se帽ales, versus una mascara `normal` con solo 1).
- [ ] Completar secciones del documento.
- [ ] Computar M茅trica _precision_ y _recall_ a partir de _threshold_ en IoU.
- [ ] Computar y gr谩ficar curva _precision_ - _recall_ para varios _threshold_ de IoU.
- [x] Cargar m谩scaras creadas con metodolog铆a actual de Edward usando `PlantDataset`.
- [X] Computar metricas de IoU para mascaras propuestas por el modelo y las mascaras creadas con metodolog铆a actual de Edward.
- [ ] _Script_ para entrenar modelo multi-clase.
- [ ] Crear clase meta-modelo para abstraer los pasos en training y evaluation, y poder reutilizar c贸digo, pero usando distintos modelos como MASK, SegFormer, etc.


## Logbook

#### 11/09/2023

Actualizaci贸n de las Figuras 3 y 4 en el documento. Se observan imagenes del conjunto de validaci贸n y comparan las m谩scaras predichas por el modelo vs. el m茅todo tradicional.


<figure>
  <img src="./assets/fig3-val-cwt-dataset.png" alt="Figure 3 - Val images">
  <figcaption><small>Fig. 3. Rows from top to bottom correspond to the input image patches, label masks (ground truth), model prediction masks, and traditional method masks from the cwt plant dataset. The Intersection Over Union (IoU) metric for each of the five cases is reported within the image in the last two rows. In almost every case, the model predictions are superior to the current method. For instance, in the first column, the predicted mask reports 0.29 IoU w.r.t. a 0.42 IoU from the mask generated by the traditional method. These observations are in a subset that was not used to train the modelan overall mean IoU of 0.52 reports the predictions vs. 0.42 in the traditional method.</small></figcaption>
</figure>


<figure>
  <img src="./assets/fig4-val-dead-dataset.png" alt="Figure 3 - Val images">
  <figcaption><small>Fig. 4. Rows from top to bottom correspond to the input image patches, label masks (ground truth), model prediction masks, and traditional method masks from the dead plant dataset. The Intersection Over Union (IoU) metric for each of the five cases is reported within the image in the last two rows. In every case, the model predictions are superior to the current method. For instance, in the first column, the predicted mask reports 0.65 IoU w.r.t. a 0.15 IoU from the mask generated by the traditional method. These observations are in a subset that was not used to train the modelan overall mean IoU of 0.47 reports the predictions vs. 0.25 in the traditional method.</small></figcaption>
</figure>

Se realizaron modificaciones en `benchmarking.py`, en particular:

* Se agreg贸 un argumento --show_n_images para mostrar las imagenes de validaci贸n con sus respectivas m谩scaras predichas por el modelo y las m谩scaras del m茅todo tradicional.
* Se eliminaron los captions de las imagenes que se guardan.

#### 14/08/2023

  * Analizando las m谩scaras alternativas obtenidas por m茅todo tradicional de Edward, pero para el subconjunto `dead`. Se encontr贸 que las m谩scaras alternativas no son blanco y negro, sino m谩s bien una imagen en escala de grises. A diferencia de las m谩scaras alternativa spara el subconjunto `cwt`. Esto se puede visualizar en el _notebook_ `playground.ipynb`, secci贸n Evaluate Benchmark, Dead dataset. **Ser谩 necesario usar un _threshold_ para determinar cuando un _pixel_ es blanco o negro en las m谩scaras alternativas**.
  * Lo anterior propone un _trade-off_ entre incorporar regiones que solo es ruido y dejar zonas que identificar los objetos de interes en la imagen. Se utiliz贸 un _threshold_ dentro de `collate_fn` en el script `benchmarking.py`:
  ```python
      if alternative_masks:
        if dataset_type == 'dead':
            # apply threshold to get a binary masks (dead alternative mask -> grayscale)
            benchmark_masks = torch.where(benchmark_masks > 0.6, 1.0, 0.0)
        return images, targets, benchmark_masks
  ```
  * Revisar observaci贸n `cwt4_55.jpg` del conjunto de entrenamiento que tanto la predicci贸n como la m谩scara del m茅todo alternativo tiene un valor de 0.
  * Adicional al csv con los resultados por observaci贸n, se generaron imagenes del input, m谩scaras, predicciones y m茅todo alternativo para crear un diagrama con la siguiente estructura para las observaciones en validaci贸n:

<center>
<img src="./assets/results-cwt-val-diagram.png" alt="lalal" width="600"/>
</center>

   * Repensar mejor la l贸gica de la configuraci贸n para crear los conjuntos de entrenamiento/validaci贸n para los distintos datasets (i.e. `cwt`, `dead`) que se comunique entre el script `train.py` y `benchmarking.py` para evitar errores de consistencia. Por ahora, todo se delega a nivel de los argumentos con los que se llama el script que debe proveer el usuario con el mismo _seed_ y _checkpoint_ del modelo que se entreno sobre la partici贸n de entrenamiento/validaci贸n generada por el _seed_.


#### 12/08/2023

  * Se modific贸 la funci贸n `get_pred_label` para que recolecte del dataloader entregado como input las m谩scaras alternativas cuando esten disponibles por `PlantDataset(..., alternative_masks=True)`.
  * Se mejoro la documentaci贸n de la funci贸n `get_pred_label` para que sea m谩s clara su utilizaci贸n.
  * Se actualiz贸 el uso de `get_pred_label` en el notebook `single-segmentation.ipynb` para que retornara el output seg煤n las nuevas modificaciones.
  * El script `benchmarking.py` carga un checkpoint, el dataset con las m谩scaras alternativas, y computa las m茅tricas de IoU para las m谩scaras alternativas y las predicciones del modelo con la ayuda de la funci贸n `get_pred_label`. Obtiene un identificador para cada observaci贸n, y guarda las m茅tricas IoU por observaci贸n, tanto las reportadas por el modelo como las propuestas por las m谩scaras alternativas, en un archivo `.csv` en la carpeta `results` con el nombre `benchmarking_<id>.csv`. Adem谩s, se obtiene el n煤mero de m谩scaras asociadas a cada observaci贸n y cuantas de estas corresponden a la se帽al a detectar (e.g. viva). El archivo con los resultados tiene la siguiente estructura:

    ```
    image_name,iou_model,iou_alternative,num_masks,normal_num_masks,split,model_ckpt
    cwt1_10.jpg,0.642349,0.53557384,4,1,train,ckpt/cwt-single-segmentation.pth
    cwt4_76.jpg,0.12558275,0.10311527,7,1,train,ckpt/cwt-single-segmentation.pth
    cwt4_55.jpg,0.0,0.0,5,1,train,ckpt/cwt-single-segmentation.pth
    cwt3_55.jpg,0.5076142,0.27609223,9,1,train,ckpt/cwt-single-segmentation.pth
    cwt3_16.jpg,0.55149746,0.48964947,4,1,train,ckpt/cwt-single-segmentation.pth
    cwt3_14.jpg,0.5455779,0.59192973,3,1,train,ckpt/cwt-single-segmentation.pth
    ```

#### 23/07/2023

  * Se cre贸 el archivo `benchmarking.py` que ser谩 el encargado de computar metricas sobre el conjunto del dataset especificado, cargando un _checkpoint_ de modelo ajustado por el script `train.py`. 
  * Adicionalmente, este _script_ deber谩 poder computar las metricas utilizando m谩scaras obtenidas por un m茅todo alternativo usando las modificaciones explicadas en la entrada 22/07/2023.

#### 22/07/2023

* Se agreg贸 funcionalidad en `PlantDataset` para cargar m谩scaras adicionales computadas por un m茅todo externo (e.g. m茅todo tradicional). 
* El proposito de esta funcionalidad es evaluar las m茅tricas de un modelo entrenado, y compararlas con las m谩scaras computadas por el m茅todo tradicional. 
* Para cargar las m谩scaras adicionales, se debe instanciar la clase `PlantDatset` de la siguiente forma:

```python
from dataset import PlantDataset, extract_ids_from_name

label2id = {'normal': 0, 'normal_cut': 1, 'noise': 2}
dataset = PlantDataset('data',
                       'cwt', 
                       'data_inventary.csv', 
                       label2id=label2id, 
                       alternative_masks=True)
```

* Luego, el m茅todo `__getitem__` de la clase `PlantDataset` devuelve un diccionario con las m谩scaras adicionales, y se puede acceder a ellas por su nombre:

```python
        if self.alternative_masks:
            alternative_mask_path = os.path.join(self.root, self.folder, 'original_labeled_imageJ_mask', self.alternative_masks[idx])
            return {
                'image': image,
                'masks': masks_path,
                'labels': labels,
                'alternative_masks': Image.open(alternative_mask_path)
            }
```

```python
dataset[10]['alternative_masks']
```

* Nota importante de la implementaci贸n, se asume que las m谩scaras tradicionales tienen estructura de carpeta igual a las imagenes del input (i.e. `dataset[10][]`). Es decir, tanto la carpeta `subset/original` como `subset/original_labeled_imageJ_mask` tienen la misma cantidad de imagenes, solo que sus nombres son distintos. Por ejemplo, `cwt1_1.jpg` y `cwt1_mask_1.jpg`. Esta es la raz贸n de los indices utilizados para extraer los digitos en el caso de las m谩sracaras cuando se instancia la clase:

```python
        if alternative_masks: 
            self.alternative_masks = []
            alternative_masks_folder = os.listdir(os.path.join(self.root, self.folder, 'original_labeled_imageJ_mask'))
            alternative_masks_folder.sort(key=lambda x: (int(re.findall(r'\d+', x.split('_')[0])[0]), 
                                                int(re.findall(r'\d+', x.split('_')[2])[0])))
```

- Se modifica la funci贸n `collate_fn` para crear DataLoaders adicionando las m谩scaras tradicionales, y aplicando las transformaciones a estas para que sean
tensores.

```python
def collate_fn(batch, target_fn=get_binary_target, alternative_masks=False):
    """
        Collate function to stack the masks as channels in the same tensor.
        get_target: function to get the target tensor from the masks and labels
            could be multi-labeling or binary.
        alternative_masks: if True, return the alternative masks for benchmarking
          in addition to the images, targets.
    """ 
    tfms = ToTensor()
    images = torch.cat([feature_extractor(example['image'], return_tensors='pt')['pixel_values'] for example in batch])
    if alternative_masks:
        # Resize to 512x512, then convert to grayscale and tensor. Finally, add 
        # a dimension for the channel (=1) with .unsqueeze(1) -> (B, 1, H, W)
        tfms_benchmark_masks = Compose([Grayscale(num_output_channels=1), ToTensor()])
        benchmark_masks = torch.cat([tfms_benchmark_masks(example['alternative_masks'].resize((512, 512))).unsqueeze(1) for example in batch])
    masks = [example['masks'] for example in batch]
    labels = [example['labels'] for example in batch]
    targets = torch.cat([target_fn(x[0], x[1], tfms, size=(512,512)) for x in zip(masks, labels)])

    # transformar a 1 cuando haya un entero distinto a 0 (semantic segmentation)
    targets = torch.where(targets > 0.0, 1.0, 0.0)
    if alternative_masks:
        return images, targets, benchmark_masks
    return images, targets
```

#### 17/07/2023

* Incorporar forma para cargar las m谩scaras del m茅todo tradicional (base) en la clase `PlantDataset`, y poder utilizarla para evaluar las m茅tricas.
* Reuni贸n de Ricardo, 
  * Reuni贸n de Edward, submascaras de la clase `normal_cut` y `noise`, apagarlos de la etiqueta. 
  * Usar el filtro anterior, 
  * Apagar con mascaras validacion


#### 27/06/2023

* Se actualiz贸 el dataset en [ruta compartida en Drive](https://drive.google.com/drive/folders/1KltqueU8bUoAnXMqhKifbpMULspNwoZm?usp=drive_link) con todas las masks del dataset dead 
* Se habilit贸 en el _script_ `train.py` _logging_ con W&B, para _trackear_ m茅tricas durante entrenamiento cada vez que se utiliza una configuraci贸n distinta de hiperpar谩metros. Se puede ver el proyecto de W&B [aqu铆](https://wandb.ai/alcazar90/plant-segmentation?workspace=user-alcazar90), y a continuaci贸n algunos de las visualizaciones que se pueden ver en el _dashboard_:

![](./assets/wandb_table.png)

<table border=0 align=center>
    <tbody>
        <tr>
     	    <td width="33%" align="center"> <img src="./assets/wandb_miou_plot.png"></td>
   	      <td width="33%" align="center"> <img src="./assets/wandb_val_loss.png"></td>
   	      <td width="33%" align="center"> <img src="./assets/wandb_train_loss.png"></td>
        </tr>
    </tbody>
</table>

* **Nota importante**, se realiz贸 modificaci贸n en la funci贸n `get_pred_label`, ahora devuelve las imagenes y probabilidades aparte de la etiqueta y la predicci贸n. Se aprovecha de computar varias cosas con la misma funci贸n, y evitar redundancia en recorrer el dataloader.

```python
# ahora
val_img, val_labels, val_preds, val_probs = get_pred_label(model, val_loader, device)
# antes                                                           
preds, labels = get_pred_label(model, val_loader, device)
```

#### 24/06/2023

**Respecto a revisiones de la clase `PlantDataset`**. Se verificaron que las m谩scaras actuales para el _dataset_ `dead` estuvieran acorde a la estructura de carpeta. A pesar de que no hay cobertura completa de etiquetado, el _dataset_ funciona seg煤n lo esperado. Ahora se puede utilizar la misma clase para instanciar el _dataset_ `cwt` y `dead` con el mismo c贸digo.

Se actualiz贸 `PlantDataset.get_masks_per_labels` para usar una expresi贸n regex e identificar el tipo de m谩scaras por el label en su nombre seg煤n el diccionario `self._label2id`, antes se encontraba hardcodeado para el _dataset_ `cwt`.

```python
def get_masks_per_labels(self):
    """ Return the number of masks per label """
    pattern = ''.join([s + '-|' if idx < len(self._label2id)-1 else s for idx, s in enumerate(self._label2id.keys())])
    get_label = lambda x: re.findall(pattern, x)[0].replace('-', '')
    out = [get_label(m) for img in self.masks for m in img]
    return np.unique(out, return_counts=True)
```

**Respecto al entrenamiento del modelo**. Se cre贸 el archivo `train.py` donde tiene solo el c贸digo necesario para entrenar un modelo y computar m茅tricas durante el entrenamiento. Se computa _intersection over union (IoU)_ para monitorear y realizar _early stopping_, usando el conjunto de validaci贸n. Lo anterior, es posible gracias a la funci贸n `get_pred_label` del archivo `evaluation.py` que recolecta en modo inferencia las predicciones, etqiuetas, y logits de todas las observaciones en un dataloader.

```python
# Collect predictions, labels, and logits from all observations in a dataloader
val_preds, val_labels, val_logits = get_pred_label(model, 
                                                   val_loader, 
                                                   device, 
                                                   return_logits=True)
```

Otras caracteristicas de `train.py` son:

* Utilizar modulo `argparser` para fijar los hiperpar谩metros y otras configuraciones de entrenamiento v铆a linea de comando.
* Computar m茅tricas de entrenamiento al final de cada _epoch_.
* Computar m茅tricas en validaci贸n dado X n煤mero de actualizaciones de gradientes que son monitoreados la variable `eval_steps`.
* Guardar _checkpoints_ del modelo cada vez que se logra mejorar la m茅trica _mean intersection over union_ de todo el conjunto de validaci贸n.
* Guardar la m茅trica IoU por observaci贸n en el conjunto de validaci贸n cada vez que se ejecuta el _pipeline_ de validaci贸n en el archivo `miou_<id>.csv` en la carpeta `results`.


Por ejemplo, podemos entrenar un modelo de la siguiente manera:

```bash
python train.py --bs 2 --epochs 20 --eval_steps 30 --lr 1e-3 --rep 2 --dataset cwt
python train.py --bs 2 --epochs 20 --eval_steps 30 --lr 1e-3 --rep 2 --dataset dead
```

Luego, podemos computar el mIoU a partir del archivo `miou_<id>.csv` directamente desde el terminal usando `awk`:

```bash
awk -F',' '{sum=0; for(i=2; i<=NF; i++){sum+=$i} average=sum/(NF-1); print average}' ./results/miou_1.csv
```

#### 23/06/2023

Se modific贸 la clase `PlantDataset(Dataset)` en `dataset.py` y se agreg贸 un nuevo par谩metro para inicializar la clase, `label2id`, que permite codificar los labels a partir de los nombres de las m谩scaras cuando se cargan a partir de las carpetas. Esto permite mayor flexibilidad para cargar las m谩scaras de los labels sobre distintos tipos de experimentos, tanto como `cwt` y `dead` que disponen de diferentes labels. A continuaci贸n se muestra un ejemplo de como se inicializa la clase `PlantDataset` dependiendo el caso:

```python
# Crear dataset con plantas vivas
label2id = {'normal': 0, 'normal_cut': 1, 'noise': 2}
cwt_dataset = PlantDataset('data', 'cwt', 'data_inventary.csv', label2id=label2id)

# Crear dataset con plantas muertas
label2id = {'dead': 0, 'dead_cut': 1, 'noise': 2}
dead_dataset = PlantDataset('data', 'dead', 'data_inventary.csv', label2id=label2id)
```

#### 15/06/2023

Luego de tener capacidad de memorizar un _batch_ de 4 imagenes (seccion anterior), y afinar un par de detalles en el loop de entrenamiento, se realiz贸 _fine-tuning_ sobre el conjunto de datos completo. Se utiliz贸 un _learning rate_ de `1e-3` y se entren贸 por 300 pasos de actualizaci贸n de par谩metros. Se utiliz贸 un _batch size_ de 2 im谩genes, y se separ贸 el conjunto de datos en 59 imagenes de entrenamiento y 10 para validaci贸n. 

Se monitoreo el _mean Intersection over Union_ (mIoU) sobre el conjunto de validaci贸n cada 25 pasos de actualizaci贸n de par谩metros, y se guard贸 un _checkpoint_ del modelo cada vez que se lograba una mejor m茅trica. Sin ajustes elaborados de hiperpar谩metros, se obtuv贸 un modelo que report贸 un 0.53 de mIoU sobre el conjunto de validaci贸n.

En vez de continuar experimentando, y entrenando el modelo, se utiliz贸 el _checkpoint_ anterior en la secci贸n _"Load a checkpoint & compute metrics"_ para computar y analizar una evaluaci贸n m谩s profunda del modelo.

Se utiliza `get_pred_label(model, val_loader, device)` para recolectar las predicciones del modelo y las etiquetas dado el dataloader del conjunto de validaci贸n. Esta informaci贸n permite computar r谩pidamente el IoU por cada ejemplo del conjunto de validaci贸n.

```python
# Collect the predictions of a model and labels from a dataloader
preds, labels = get_pred_label(model, val_loader, device)

# Compute IoU per example
val_iou = compute_iou(preds, labels)
print("IoU per each validation example:\n")
val_iou
> IoU per each validation example:

> tensor([0.6895, 0.4673, 0.7664, 0.0026, 0.5333, 0.4500, 0.6005, 0.7132, 0.3637,
        0.6716])
```
<center>
<img src="./assets/best-miou-val-prediction-masks.png" alt="lalal" width="700"/>

<img src="./assets/best-miou-val-truth-masks.png" alt="lalal" width="700"/>
</center>



* En general, los resultados son bastante buenos, 6/10 imagenes tienen un IoU mayor a 0.5, y 3/10 tienen un IoU mayor a 0.6.
* Se detecto un error en la m谩scara de la imagen 4, la que reporta un IoU de 0.0026. Esto se debe a que la m谩scara de la imagen 4 tiene un label `normal` que no coincide con la imagen original. Esto afecta el promedio de IoU general, y se debe tener en cuenta para futuras evaluaciones.
* Se observa en las imagenes 2, 5, 7, 9 que el modelo predice informaci贸n adicional que no aparece en las mascaras, esto significa que el modelo esta prediciendo las otras mascaras con etiquetas `normal-cut` y `noise`. Por lo tanto, esto puede ser una buena se帽al si se incorporan estos masks adicionales para controlar esto, y significar铆a que la m茅trica IoU aumentaria en estos casos, considerando todo lo dem谩s constante.

En la siguiente iteraci贸n, continuar mejorando la evaluaci贸n del modelo, y computar las siguientes m茅tricas resumidas en la Figura 6.27 del libro de Szeliski, que se muestra a continuaci贸n:


<center>
<img src="./assets/fig6-27-iou-precision-recall-szeliski-book.png" alt="Fig 6.27 Szeliski's computer vision book" width="700"/>
</center>


#### 14/06/2023

El archivo `single-segmentation.ipynb` se puede entrenar un modelo sobre el conjunto de datos `cwt`, solo para detectar el label `normal`. En la creaci贸n del _target_ a partir de las m谩scaras, se utiliza `get_binary_mask` para convertir las masks asociadas al label `normal` en `1` y el resto de labels se convierten en 0. 

En la siguiente imagen se puede ver el resultado de la segmentaci贸n _overfitteando_ un batch de 4 im谩genes con label `normal`:

<center>
<img src="./assets/single-segmentation-overfitting-a-batch-without-training.png" alt="lalal" width="600"/>

<img src="./assets/single-segmentation-overfitting-a-batch-preds.png" alt="lalal" width="600"/>


<img src="./assets/single-segmentation-overfitting-a-batch-truth.png" alt="lalal" width="600"/>
</center>

Importante verificar luego del entrenamiento sobre el conjunto de datos completos, la influencia de elementos como `normal-cut` o `noise`.

Se deben tener la capacidad de computar la m茅trica de IoU para cada predicci贸n, as铆 luego ocuparlo tanto en el conjunto de validaci贸n y pruebas, para clasificar las predicciones dado cierto _threshold_ como correctas e incorrectas. Esto permitir谩 computar otras m茅tricas como _precision_ y _recall_.


## Instructions

- Los _checkpoints_ con los modelos se encuentran en el directorio `ckpt`.


## Citing

```
@misc{TBPlantSegmentation,
  authors = {Alc谩zar, Crist贸bal}, {Chocano, Edward}, {Flores, Ricardo}
  title = {SegPlantFormer: A Transformer-based Model for Plant Semantic Segmentation},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/alcazar90/plant-segmentation}},
}
```
